{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to the Toto module\n",
    "%cd ../../boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from utils.leaderboard import (\n",
    "    NON_ZERO_METRICS,\n",
    "    ZERO_METRICS,\n",
    "    load_model_results,\n",
    "    separate_zero_inflated_data,\n",
    "    process_benchmark_model_results,\n",
    "    get_separate_zero_inflated_leaderboard,\n",
    "    shifted_gmean,\n",
    ")\n",
    "\n",
    "from utils.breakdown import (\n",
    "    METRIC_NAMES,\n",
    "    add_agg_columns,\n",
    "    get_breakdown_table,\n",
    "    expand_complex_column,\n",
    ")\n",
    "\n",
    "BOOMLET_BENCHMARK = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full benchmark leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfs_names = load_model_results('results/', BOOMLET_BENCHMARK)\n",
    "non_zero_dfs, zero_dfs = separate_zero_inflated_data(dfs)\n",
    "\n",
    "non_zero_dfs = process_benchmark_model_results(\n",
    "    is_scale_by_naive=True,\n",
    "    dfs=non_zero_dfs,\n",
    "    metrics=NON_ZERO_METRICS,\n",
    ")\n",
    "\n",
    "zero_dfs = process_benchmark_model_results(\n",
    "    is_scale_by_naive=False, \n",
    "    dfs=zero_dfs,\n",
    "    metrics=ZERO_METRICS,\n",
    ")\n",
    "\n",
    "os.makedirs('leaderboards/', exist_ok=True)\n",
    "leaderboard = get_separate_zero_inflated_leaderboard(\n",
    "        non_zero_dfs=non_zero_dfs,\n",
    "        zero_dfs=zero_dfs,\n",
    "        dfs_names=dfs_names,\n",
    "        agg_func=shifted_gmean,\n",
    "        non_zero_metrics=NON_ZERO_METRICS,\n",
    "        zero_metrics=ZERO_METRICS,\n",
    "    )\n",
    "\n",
    "leaderboard.to_csv(f'leaderboards/boom{\"let_\" if BOOMLET_BENCHMARK else \"_\"}leaderboard.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_method = 'shifted_gmean'\n",
    "out_dir = 'breakdown_tabels'\n",
    "agg_columns = ['real_term', 'type', 'domain']\n",
    "boom_properties = json.load(open('boomlet_properties.json' if BOOMLET_BENCHMARK else 'boom_properties.json', \"r\"))\n",
    "dfs = add_agg_columns(non_zero_dfs, agg_columns, boom_properties)\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def save_breakdown(dfs_input, agg_column):\n",
    "    tables = get_breakdown_table(dfs_input, dfs_names, agg_column, NON_ZERO_METRICS, agg_method)\n",
    "    for metric_key, table in tables.items():\n",
    "        print(agg_column, metric_key, agg_method)\n",
    "        table.round(3).to_csv(\n",
    "            f\"{out_dir}/{agg_column}_{METRIC_NAMES.get(metric_key, metric_key.replace('/', '_'))}_{agg_method}.csv\"\n",
    "        )\n",
    "\n",
    "for col in ['full_benchmark', 'real_term','type']:\n",
    "    save_breakdown(dfs, col)\n",
    "\n",
    "for col in ['domain']:\n",
    "    save_breakdown(expand_complex_column(dfs, col), col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
