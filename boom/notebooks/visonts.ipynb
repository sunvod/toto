{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50eb0a9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "source": [
    "# Running VisionTS models on BOOM benchmark\n",
    "\n",
    "This notebook is adapted from the [GiftEval repository](https://github.com/SalesforceAIResearch/gift-eval/tree/main/notebooks) and shows how to run the VisionTS on the BOOM benchmark.\n",
    "\n",
    "Make sure you download the BOOM benchmark and set the `BOOM` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class from GiftEval to load the data and run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733238fd",
   "metadata": {},
   "source": [
    "Download BOOM datasets. Calling `download_boom_benchmark` also sets the `BOOM` environment variable with the correct path, which is needed for running the evals below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2a2cf-ac0e-40d7-920f-12003c06a333",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-20T23:01:58.669161Z",
     "iopub.status.busy": "2025-04-20T23:01:58.668828Z",
     "iopub.status.idle": "2025-04-20T23:02:01.452865Z",
     "shell.execute_reply": "2025-04-20T23:02:01.452277Z",
     "shell.execute_reply.started": "2025-04-20T23:01:58.669133Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from dataset_utils import download_boom_benchmark\n",
    "\n",
    "boom_path = \"ChangeMe\"\n",
    "download_boom_benchmark(boom_path)\n",
    "load_dotenv()\n",
    "\n",
    "dataset_properties_map = json.load(open(\"../dataset_properties.json\"))\n",
    "all_datasets = list(dataset_properties_map.keys())\n",
    "print(len(all_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0231d-1ab6-482c-9fb1-7c31327981b2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-20T23:02:01.454125Z",
     "iopub.status.busy": "2025-04-20T23:02:01.453786Z",
     "iopub.status.idle": "2025-04-20T23:02:01.491025Z",
     "shell.execute_reply": "2025-04-20T23:02:01.490532Z",
     "shell.execute_reply.started": "2025-04-20T23:02:01.454082Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MAE,\n",
    "    MAPE,\n",
    "    MASE,\n",
    "    MSE,\n",
    "    MSIS,\n",
    "    ND,\n",
    "    NRMSE,\n",
    "    RMSE,\n",
    "    SMAPE,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852158ee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-20T23:02:04.466197Z",
     "iopub.status.busy": "2025-04-20T23:02:04.465812Z",
     "iopub.status.idle": "2025-04-20T23:02:12.002110Z",
     "shell.execute_reply": "2025-04-20T23:02:12.001476Z",
     "shell.execute_reply.started": "2025-04-20T23:02:04.466170Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from gluonts.ev.metrics import MAE, MASE, MSE, ND, NRMSE, SMAPE\n",
    "from gluonts.model.evaluation import evaluate_forecasts\n",
    "from visionts import VisionTS, freq_to_seasonality_list\n",
    "\n",
    "POSSIBLE_SEASONALITIES = {\n",
    "    \"S\": [3600],  # 1 hour\n",
    "    \"T\": [1440, 10080],  # 1 day or 1 week\n",
    "    \"H\": [24],  # 1 day or 1 week\n",
    "    \"D\": [7, 30, 365],  # 1 week, 1 month or 1 year\n",
    "    \"W\": [52, 4], # 1 year or 1 month\n",
    "    \"M\": [12, 6, 3], # 3 months, 6 months or 1 year\n",
    "    \"B\": [5],\n",
    "    \"Q\": [4, 2], # 6 months or 1 year\n",
    "}\n",
    "\n",
    "def imputation_nan(array):\n",
    "    \"\"\"\n",
    "    Impute missing value using Naive forecasting.\n",
    "    \"\"\"\n",
    "    not_nan_mask = ~np.isnan(array)\n",
    "    if not_nan_mask.all():\n",
    "        return array\n",
    "    if not not_nan_mask.any():\n",
    "        return np.zeros_like(array)\n",
    "\n",
    "    array_imputed = np.copy(array)\n",
    "    for i in range(len(array)):\n",
    "        if not not_nan_mask[i]:\n",
    "            array_imputed[i] = array_imputed[i - 1]\n",
    "    return array_imputed\n",
    "\n",
    "\n",
    "def forecast(model: VisionTS, train_list: list, test_list: list, batch_size, device, periodicity):\n",
    "    # We combine testing data with the context lengths\n",
    "    seq_len_to_group_data = {}\n",
    "    for i in range(len(train_list)):\n",
    "        train_len = len(train_list[i])\n",
    "        if train_len not in seq_len_to_group_data:\n",
    "            seq_len_to_group_data[train_len] = [[], [], []] # index, input, output\n",
    "        seq_len_to_group_data[train_len][0].append(i)\n",
    "        seq_len_to_group_data[train_len][1].append(train_list[i])\n",
    "        seq_len_to_group_data[train_len][2].append(test_list[i])\n",
    "    \n",
    "    forecast_np = {} # raw index -> forecast\n",
    "    for train_len in seq_len_to_group_data:\n",
    "        cur_idx_list, cur_train, cur_test = seq_len_to_group_data[train_len]\n",
    "        convert = lambda array: torch.FloatTensor(\n",
    "            einops.rearrange(np.array(array), 'b t -> b t 1')\n",
    "        ).to(device)\n",
    "        cur_train = convert(cur_train)\n",
    "        cur_test = convert(cur_test)\n",
    "        context_len = cur_train.shape[1]\n",
    "        pred_len = cur_test.shape[1]\n",
    "        model.update_config(context_len=context_len, pred_len=pred_len, periodicity=periodicity)\n",
    "\n",
    "        for batch_i in range(int(math.ceil(len(cur_train) / batch_size))):\n",
    "            batch_start = batch_i * batch_size\n",
    "            if batch_start >= len(cur_train):\n",
    "                continue\n",
    "            batch_end = batch_start + batch_size\n",
    "            if batch_end > len(cur_train):\n",
    "                batch_end = len(cur_train)\n",
    "\n",
    "            cur_batch_train = cur_train[batch_start:batch_end]\n",
    "            cur_batch_pred = model(cur_batch_train, fp64=True) # [b t 1]\n",
    "            for i in range(len(cur_batch_pred)):\n",
    "                cur_idx = cur_idx_list[batch_start + i]\n",
    "                assert cur_idx not in forecast_np\n",
    "                forecast_np[cur_idx] = cur_batch_pred[i, :, 0].detach().cpu().numpy()\n",
    "    return np.stack([forecast_np[i] for i in range(len(train_list))])\n",
    "\n",
    "\n",
    "def convert_context_len(context_len, no_periodicity_context_len, periodicity):\n",
    "    if periodicity == 1:\n",
    "        context_len = no_periodicity_context_len\n",
    "    # Round context length to the integer multiples of the period\n",
    "    context_len = int(round(context_len / periodicity)) * periodicity\n",
    "    return context_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6f190-4489-44a6-95fc-746412585738",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-20T23:02:12.003555Z",
     "iopub.status.busy": "2025-04-20T23:02:12.003135Z",
     "iopub.status.idle": "2025-04-20T23:02:12.044306Z",
     "shell.execute_reply": "2025-04-20T23:02:12.043821Z",
     "shell.execute_reply.started": "2025-04-20T23:02:12.003532Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "class visionts_wrapper:\n",
    "    def __init__(self, context_len, no_periodicity_context_len, freq, device=\"cuda:0\", checkpoint_dir=\"./ckpt\", mae_arch=\"mae_base\", batch_size=5, periodicity=\"autotune\",):\n",
    "        self.batch_size = batch_size\n",
    "        self.model = VisionTS(mae_arch, ckpt_dir=checkpoint_dir).to(device)\n",
    "        self.periodicity = periodicity\n",
    "        self.device = device\n",
    "        self.freq = freq\n",
    "        self.context_len = context_len\n",
    "        self.no_periodicity_context_len=no_periodicity_context_len\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        data_train = [imputation_nan(x['target']) for x in test_data.input]\n",
    "        data_test = [x['target'] for x in test_data.label]\n",
    "        pred_len = len(data_test[0])\n",
    "\n",
    "        if self.periodicity == \"autotune\":\n",
    "            seasonality_list = freq_to_seasonality_list(self.freq, POSSIBLE_SEASONALITIES)\n",
    "            best_valid_mae = float('inf')\n",
    "            best_valid_p = 1\n",
    "            for periodicity in tqdm(seasonality_list, desc='validate seasonality'):\n",
    "                cur_context_len = convert_context_len(self.context_len, self.no_periodicity_context_len, periodicity)\n",
    "    \n",
    "                val_train = [x[-cur_context_len-pred_len:-pred_len] for x in data_train]\n",
    "                val_test = [x[-pred_len:] for x in data_train]\n",
    "                val_forecast = forecast(self.model, val_train, val_test, self.batch_size, self.device, periodicity)\n",
    "                val_mae = np.abs(np.asarray(val_test) - val_forecast).mean()\n",
    "                if val_mae < best_valid_mae:\n",
    "                    best_valid_p = periodicity\n",
    "                    best_valid_mae = val_mae\n",
    "                    tqdm.write(f\"autotune: P = {periodicity} | valid mae = {val_mae}, accept!\")\n",
    "                else:\n",
    "                    tqdm.write(f\"autotune: P = {periodicity} | valid mae = {val_mae}, reject!\")\n",
    "            periodicity = best_valid_p\n",
    "            print(\"finishing autotuning, best period =\", periodicity)\n",
    "        elif self.periodicity == \"freq\":\n",
    "            periodicity = freq_to_seasonality_list(self.freq, POSSIBLE_SEASONALITIES)[0]\n",
    "        else:\n",
    "            periodicity = int(self.periodicity)\n",
    "\n",
    "        cur_context_len = convert_context_len(self.context_len, self.no_periodicity_context_len, periodicity)\n",
    "        train = [x[-cur_context_len:] for x in data_train]\n",
    "        forecast_values = forecast(self.model, train, data_test, self.batch_size, self.device, periodicity)\n",
    "        # print(forecast_values.shape)\n",
    "        sample_forecasts = []\n",
    "        for item, ts in zip(forecast_values, test_data.input):\n",
    "            forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "            sample_forecasts.append(\n",
    "                SampleForecast(\n",
    "                    samples=np.reshape(item, (1, -1)), start_date=forecast_start_date\n",
    "                )\n",
    "            )\n",
    "\n",
    "        metrics_df = evaluate_forecasts(\n",
    "            sample_forecasts,\n",
    "            test_data=test_data,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "        return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef7493",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we have our predictor class, we can use it to predict on the boom benchmark datasets. We will use the `evaluate_model` function from `gluonts` to evaluate the model. We are going to store the results in a csv file called `all_results.csv` under the `results/visionts` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719c3b4-1564-44e8-8850-e91134001e5b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-20T23:04:09.055994Z",
     "iopub.status.busy": "2025-04-20T23:04:09.055641Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from gift_eval.data import Dataset\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Iterate over all available datasets\n",
    "model_name = \"visionts\"\n",
    "output_dir = f\"ChangeMe/{model_name}/\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"all_results.csv\")\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "            \"dataset_size\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "for ds_num, ds_name in enumerate(all_datasets):\n",
    "    print(f\"Processing dataset: {ds_name} ({ds_num + 1} of {len(all_datasets)})\")\n",
    "    dataset_term = dataset_properties_map[ds_name][\"term\"]\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (term == \"medium\" or term == \"long\") and dataset_term == \"short\":\n",
    "            continue\n",
    "        ds_freq = dataset_properties_map[ds_name][\"frequency\"]\n",
    "        ds_config = f\"{ds_name}/{ds_freq}/{term}\"\n",
    "\n",
    "        # Initialize the dataset, since Moirai support multivariate time series forecast, it does not require\n",
    "        # to convert the original data into univariate\n",
    "        to_univariate = False if Dataset(name=ds_name, term=term,to_univariate=False, storage_env_var=\"BOOM\").target_dim == 1 else True\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate, storage_env_var=\"BOOM\")\n",
    "        dataset_size = len(dataset.test_data)\n",
    "        print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "        model = visionts_wrapper(2000, 2000, dataset.freq[0], periodicity=1)\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "        res = model.predict(dataset.test_data)\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    ds_config,\n",
    "                    \"visonts\",\n",
    "                    res[\"MSE[mean]\"][0],\n",
    "                    res[\"MSE[0.5]\"][0],\n",
    "                    res[\"MAE[0.5]\"][0],\n",
    "                    res[\"MASE[0.5]\"][0],\n",
    "                    res[\"MAPE[0.5]\"][0],\n",
    "                    res[\"sMAPE[0.5]\"][0],\n",
    "                    res[\"MSIS\"][0],\n",
    "                    res[\"RMSE[mean]\"][0],\n",
    "                    res[\"NRMSE[mean]\"][0],\n",
    "                    res[\"ND[0.5]\"][0],\n",
    "                    res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                    dataset_properties_map[ds_name][\"domain\"],\n",
    "                    dataset_properties_map[ds_name][\"num_variates\"],\n",
    "                    dataset_size,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c27950",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/visonts` folder containing the results for the Timer model on the boom benchmark. The csv file will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe85981-77a0-4c38-9cab-17c96cf3fde8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-04T00:36:44.078212Z",
     "iopub.status.busy": "2025-04-04T00:36:44.077904Z",
     "iopub.status.idle": "2025-04-04T00:36:44.155788Z",
     "shell.execute_reply": "2025-04-04T00:36:44.155265Z",
     "shell.execute_reply.started": "2025-04-04T00:36:44.078189Z"
    },
    "frozen": false,
    "tags": [
     "unsafe_output"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(output_dir + \"/all_results.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "dd-sharing": {
   "allowed_groups": [
    "subproduct-datascience",
    "combined-data-science",
    "team-largemodelfoundationsresearch",
    ""
   ],
   "allowed_users": [
    ""
   ],
   "retention_period": "90"
  },
  "kernelspec": {
   "display_name": "visionts_eval_env",
   "language": "python",
   "name": "visionts_eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
